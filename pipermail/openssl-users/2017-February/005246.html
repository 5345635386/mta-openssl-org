<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [openssl-users] BN_MUL_MONT for ARM64 v8
   </TITLE>
   <LINK REL="Index" HREF="https://mta.openssl.org/pipermail/openssl-users/2017-February/index.html" >
   <LINK REL="made" HREF="mailto:openssl-users%40openssl.org?Subject=Re%3A%20%5Bopenssl-users%5D%20BN_MUL_MONT%20for%20ARM64%20v8&In-Reply-To=%3CCAJNqtur2pQ%2B%2B3tYMt9afcP4NJnT0ubPLV7dgYVWcqVxc_iAxYw%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="005242.html">
   <LINK REL="Next"  HREF="005249.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[openssl-users] BN_MUL_MONT for ARM64 v8</H1>
    <B>Vijay Chander</B> 
    <A HREF="mailto:openssl-users%40openssl.org?Subject=Re%3A%20%5Bopenssl-users%5D%20BN_MUL_MONT%20for%20ARM64%20v8&In-Reply-To=%3CCAJNqtur2pQ%2B%2B3tYMt9afcP4NJnT0ubPLV7dgYVWcqVxc_iAxYw%40mail.gmail.com%3E"
       TITLE="[openssl-users] BN_MUL_MONT for ARM64 v8">vijay.chander at gmail.com
       </A><BR>
    <I>Tue Feb  7 16:42:38 UTC 2017</I>
    <P><UL>
        <LI>Previous message: <A HREF="005242.html">[openssl-users] BN_MUL_MONT for ARM64 v8
</A></li>
        <LI>Next message: <A HREF="005249.html">[openssl-users] BN_MUL_MONT for ARM64 v8
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#5246">[ date ]</a>
              <a href="thread.html#5246">[ thread ]</a>
              <a href="subject.html#5246">[ subject ]</a>
              <a href="author.html#5246">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Thanks Andy.

A72 is running 1GHz compared to x86 at 2.1Ghz. So that should hopefully get
down to -1:5.
There is no L3 cache on the A72 eval board and performance counters do show
9x more DRAM accesses for ARM compared to x86.

Will check out Mongoose and Kyro.

Do you know of any good hardware crypto intellectual property like synopsis
for example which can help in asymmetric crypto part of TLS handshake ?

Thanks,

Vijay


On Feb 7, 2017 7:06 AM, &quot;Andy Polyakov&quot; &lt;<A HREF="../../../mailman/listinfo/openssl-users.html">appro at openssl.org</A>&gt; wrote:

&gt;<i>   Is big number montogomery multiplication as optimized as it can be for
</I>&gt;<i> ARM64 as compared to X86-64 from the latest openssl github ?
</I>&gt;<i>   We are not seeing vmull ( or pmull/pmull2) instructions in
</I>&gt;<i> armv8-mont.pl &lt;<A HREF="http://armv8-mont.pl">http://armv8-mont.pl</A>&gt;.
</I>&gt;<i>
</I>&gt;<i>    On an ARM cortex-A72 (1GHz)  and E5-2620 (2.1 Ghz)  we are seeing an
</I>&gt;<i> order of 10 difference in RSA signing perf for 2048 bit keys.
</I>
When it comes to performance correct question actually is not what is
the result in absolute terms, but how far is it from possible maximum
for specific processor [taking into consideration all the factors from
ISA capabilities and specific hardware implementation]. So that implying
that 10x difference between processors in question is result of
insufficient optimization for one is somewhat unjustified. Well, to be
completely honest there are some minor tricks one can pull on ARMv8, but
it will only make the gap a *little* bit smaller. Or in other words suck
it up, that's the way Cortex [currently?] is. If it's so critical *and*
you're in position to choose processor, then Samsung Mongoose core would
be much better choice (but I don't know anything about Qualcomm Kryo).
Yet, even though it would be better choice, it still wouldn't actually
close the gap, so don't get your hopes too high :-)

As for not seeing vector instructions. Pmull[2] is about something
completely different. As for vmull you have to recognize that it's
limited by 32-bit inputs and there is no carry handling in vector
instructions. This means that it would take more instructions to do same
job, even though you perform pair of multiplications in one vector
instruction. Well, it's more complicated than just amount of
instructions, but nevertheless, scalar 64x64 multiplication with carry
processing offered by ARMv8 ISA does deliver better result than 128-bit
vector instructions would.

--
openssl-users mailing list
To unsubscribe: <A HREF="../../../mailman/listinfo/openssl-users.html">https://mta.openssl.org/mailman/listinfo/openssl-users</A>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://mta.openssl.org/pipermail/openssl-users/attachments/20170207/96e0257b/attachment.html">http://mta.openssl.org/pipermail/openssl-users/attachments/20170207/96e0257b/attachment.html</A>&gt;
</PRE>



<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="005242.html">[openssl-users] BN_MUL_MONT for ARM64 v8
</A></li>
	<LI>Next message: <A HREF="005249.html">[openssl-users] BN_MUL_MONT for ARM64 v8
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#5246">[ date ]</a>
              <a href="thread.html#5246">[ thread ]</a>
              <a href="subject.html#5246">[ subject ]</a>
              <a href="author.html#5246">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="../../../mailman/listinfo/openssl-users.html">More information about the openssl-users
mailing list</a><br>
</body></html>
